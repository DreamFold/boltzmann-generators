{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import mdtraj\n",
    "\n",
    "import boltzgen.zmatrix as zmatrix\n",
    "import boltzgen.internal as ics\n",
    "import boltzgen.mixed as mixed\n",
    "\n",
    "import normflow as nf\n",
    "from boltzgen.flows import CoordinateTransform\n",
    "from boltzgen.distributions import Boltzmann, BoltzmannParallel, TransformedBoltzmann, TransformedBoltzmannParallel\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from autograd import grad\n",
    "from autograd import numpy as np\n",
    "from simtk import openmm as mm\n",
    "from simtk import unit\n",
    "from simtk.openmm import app\n",
    "from openmmtools.testsystems import AlanineDipeptideVacuum\n",
    "\n",
    "# Load the alanine dipeptide trajectory\n",
    "aldp_traj = mdtraj.load('alanine_dipeptide/trajectory/aldp100000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up coordinate transformation\n",
    "\n",
    "z_matrix = [\n",
    "    (0, [1, 4, 6]),\n",
    "    (1, [4, 6, 8]),\n",
    "    (2, [1, 4, 0]),\n",
    "    (3, [1, 4, 0]),\n",
    "    (4, [6, 8, 14]),\n",
    "    (5, [4, 6, 8]),\n",
    "    (7, [6, 8, 4]),\n",
    "    (11, [10, 8, 6]),\n",
    "    (12, [10, 8, 11]),\n",
    "    (13, [10, 8, 11]),\n",
    "    (15, [14, 8, 16]),\n",
    "    (16, [14, 8, 6]),\n",
    "    (17, [16, 14, 15]),\n",
    "    (18, [16, 14, 8]),\n",
    "    (19, [18, 16, 14]),\n",
    "    (20, [18, 16, 19]),\n",
    "    (21, [18, 16, 19])\n",
    "]\n",
    "\n",
    "cart_indices = [6, 8, 9, 10, 14]\n",
    "\n",
    "aldp_traj.center_coordinates()\n",
    "\n",
    "# superpose on the backbone\n",
    "ind = aldp_traj.top.select(\"backbone\")\n",
    "\n",
    "aldp_traj.superpose(aldp_traj, 0, atom_indices=ind, ref_atom_indices=ind)\n",
    "\n",
    "# Gather the training data into a pytorch Tensor with the right shape\n",
    "training_data = aldp_traj.xyz\n",
    "n_atoms = training_data.shape[1]\n",
    "n_dim = n_atoms * 3\n",
    "training_data_npy = training_data.reshape(-1, n_dim)\n",
    "training_data = torch.from_numpy(training_data_npy.astype(\"float64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up simulation object for energy computation\n",
    "\n",
    "temperature = 1000\n",
    "\n",
    "testsystem = AlanineDipeptideVacuum(constraints=None)\n",
    "implicit_sim = app.Simulation(testsystem.topology,\n",
    "                              testsystem.system,\n",
    "                              mm.LangevinIntegrator(temperature * unit.kelvin , 1.0 / unit.picosecond, 1.0 * unit.femtosecond),\n",
    "                              mm.Platform.getPlatformByName('Reference')#,\n",
    "                              #{'Precision': 'double'}\n",
    "                              )\n",
    "implicit_sim.context.setPositions(testsystem.positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up model\n",
    "\n",
    "# Define flows\n",
    "K = 5\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Set prior and q0\n",
    "p = Boltzmann(implicit_sim.context, temperature, energy_cut=1e2, energy_max=1e20)\n",
    "\n",
    "\n",
    "transform = CoordinateTransform(training_data, 66, z_matrix, cart_indices)\n",
    "\n",
    "p_ = TransformedBoltzmannParallel(testsystem, temperature, energy_cut=1e2,\n",
    "                                  energy_max=1e20, transform=transform)\n",
    "p__ = BoltzmannParallel(testsystem, temperature, energy_cut=1e2, energy_max=1e20)\n",
    "\n",
    "latent_size = 60\n",
    "hidden_units = 128\n",
    "q0 = nf.distributions.DiagGaussian(latent_size, trainable=False)\n",
    "\n",
    "b = torch.Tensor([1 if i % 2 == 0 else 0 for i in range(latent_size)])\n",
    "flows = []\n",
    "for i in range(K):\n",
    "    # Add two alternating Real NVP layers, and ActNorm layer, and a MCMC layer\n",
    "    # Real NVP layers\n",
    "    s = nf.nets.MLP([latent_size, hidden_units, hidden_units, hidden_units, latent_size])\n",
    "    t = nf.nets.MLP([latent_size, hidden_units, hidden_units, hidden_units, latent_size])\n",
    "    flows += [nf.flows.MaskedAffineFlow(b, s, t)]\n",
    "    s = nf.nets.MLP([latent_size, hidden_units, hidden_units, hidden_units, latent_size])\n",
    "    t = nf.nets.MLP([latent_size, hidden_units, hidden_units, hidden_units, latent_size])\n",
    "    flows += [nf.flows.MaskedAffineFlow(1 - b, s, t)]\n",
    "    # ActNorm\n",
    "    flows += [nf.flows.ActNorm(latent_size)]\n",
    "    # MCMC layer\n",
    "    dist = nf.distributions.LinearInterpolation(p_, q0, (i + 1) / K)\n",
    "    proposal = nf.distributions.DiagGaussianProposal((latent_size,),\n",
    "                                                     0.1 * np.ones(latent_size))\n",
    "    flows += [nf.flows.MetropolisHastings(dist, proposal, 20)]\n",
    "flows += [transform]\n",
    "\n",
    "# Construct flow model\n",
    "nfm = nf.NormalizingFlow(q0=q0, flows=flows, p=p)\n",
    "\n",
    "# Move model on GPU if available\n",
    "enable_cuda = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n",
    "nfm = nfm.to(device)\n",
    "nfm = nfm.double()\n",
    "#nfm = nfm.float()\n",
    "\n",
    "# Initialize ActNorm\n",
    "ind = torch.randint(len(training_data), (256, ))\n",
    "x = training_data[ind, :].double().to(device)\n",
    "#x = training_data[ind, :].float().to(device)\n",
    "#x.requires_grad = True\n",
    "from time import time\n",
    "t = time()\n",
    "kld = nfm.forward_kld(x)\n",
    "print(time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "num_samples = 32\n",
    "max_iter = 10\n",
    "trans_iter = 8000\n",
    "n_data = len(training_data)\n",
    "eval_rkld = 10\n",
    "\n",
    "\n",
    "loss_hist = np.array([])\n",
    "fkld_hist = np.array([])\n",
    "rkld_hist = np.array([])\n",
    "\n",
    "optimizer = torch.optim.AdamW(nfm.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "for it in tqdm(range(max_iter)):\n",
    "    #nfm.p.alpha = np.max([0., 1 - it / trans_iter])\n",
    "    optimizer.zero_grad()\n",
    "    ind = torch.randint(n_data, (batch_size, ))\n",
    "    x = training_data[ind, :].double().to(device)\n",
    "    fkld = nfm.forward_kld(x)\n",
    "    #rkld = nfm.reverse_kld(num_samples=num_samples)\n",
    "    loss = fkld #+ rkld\n",
    "    if not torch.isnan(loss) and loss < 0:\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_value_(nfm.parameters(), .01)\n",
    "        #gradient_norm = torch.nn.utils.clip_grad.clip_grad_norm_(nfm.parameters(), 100.)\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n",
    "    fkld_hist = np.append(fkld_hist, fkld.to('cpu').data.numpy())\n",
    "    #rkld_hist = np.append(rkld_hist, rkld.to('cpu').data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist[loss_hist > 0] = np.nan\n",
    "plt.plot(loss_hist)\n",
    "plt.show()\n",
    "#plt.plot(fkld_hist)\n",
    "#plt.show()\n",
    "#plt.plot(rkld_hist)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfm.eval()\n",
    "\n",
    "z_np = np.zeros((0, 60))\n",
    "x_np = np.zeros((0, 66))\n",
    "log_p_np = np.zeros((0,))\n",
    "log_q_np = np.zeros((0,))\n",
    "for i in tqdm(range(10)):\n",
    "    z, log_q = nfm.sample(1000)\n",
    "    x_np = np.concatenate((x_np, z.cpu().data.numpy()))\n",
    "    log_p = nfm.p.log_prob(z)\n",
    "    z, _ = nfm.flows[-1].inverse(z)\n",
    "    z_np_ = z.cpu().data.numpy()\n",
    "    log_p_np_ = log_p.cpu().data.numpy()\n",
    "    log_q_np_ = log_q.cpu().data.numpy()\n",
    "    z_np = np.concatenate((z_np, z_np_))\n",
    "    log_p_np = np.concatenate((log_p_np, log_p_np_))\n",
    "    log_q_np = np.concatenate((log_q_np, log_q_np_))\n",
    "\n",
    "\n",
    "z_d = training_data[::10].double().to(device)\n",
    "#z_d = training_data[::10].float().to(device)\n",
    "#z_d.requires_grad = True\n",
    "log_p_d = nfm.p.log_prob(z_d)\n",
    "z_d, _ = nfm.flows[-1].inverse(z_d)\n",
    "z_d_np = z_d.cpu().data.numpy()\n",
    "\n",
    "log_p_d_np = log_p_d.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(60):\n",
    "    print(i)\n",
    "    plt.hist(z_d_np[:, i], bins=100, alpha=0.5, label='data', range=[-3.1, 3.1])\n",
    "    plt.hist(z_np[:, i], bins=100, alpha=0.5, label='samples', range=[-3.1, 3.1])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj\n",
    "Z_indices = np.array([[4, 6, 8, 14],\n",
    "                      [11, 10, 8, 6],\n",
    "                      [16, 14, 8, 6],\n",
    "                      [1, 4, 6, 8],\n",
    "                      [5, 4, 6, 8],\n",
    "                      [7, 6, 8, 4],\n",
    "                      [12, 10, 8, 4],\n",
    "                      [13, 10, 8, 11],\n",
    "                      [15, 14, 8, 16],\n",
    "                      [18, 16, 14, 8],\n",
    "                      [0, 1, 4, 6],\n",
    "                      [17, 16, 14, 15], \n",
    "                      [19, 18, 16, 14],\n",
    "                      [2, 1, 4, 0],\n",
    "                      [3, 1, 4, 0],\n",
    "                      [20, 18, 16, 19],\n",
    "                      [21, 18, 16, 19]])\n",
    "\n",
    "training_data_traj = mdtraj.load('/alanine_dipeptide/trajectory/aldp100000.h5')\n",
    "torsions_train = mdtraj.compute_dihedrals(training_data_traj, Z_indices)\n",
    "\n",
    "ala2_pdb = mdtraj.load('alanine_dipeptide/alanine-dipeptide.pdb').topology\n",
    "gen_data_traj = mdtraj.Trajectory(x_np.reshape(-1, 22, 3), ala2_pdb)\n",
    "torsions_gen = mdtraj.compute_dihedrals(gen_data_traj, Z_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_convolution(x, kernel):\n",
    "    x_padded = np.concatenate([x, x, x])\n",
    "    y_padded = np.convolve(x_padded, kernel, mode='same')\n",
    "    return y_padded[x.size:-x.size]\n",
    "\n",
    "torsion_hists_train = []\n",
    "torsion_hists_gen = []\n",
    "xticks = None\n",
    "\n",
    "for i in range(torsions_train.shape[1]):\n",
    "    htrain, e = np.histogram(torsions_train[:, i], 50, range=(-np.pi, np.pi), density=True);\n",
    "    xticks = 0.5 * (e[1:] + e[:-1])\n",
    "    hgen, _ = np.histogram(torsions_gen[:, i], 50, range=(-np.pi, np.pi), density=True);\n",
    "    \n",
    "    htrain = periodic_convolution(htrain, [0.25, 0.5, 1.0, 0.5, 0.25])\n",
    "    hgen = periodic_convolution(hgen, [0.25, 0.5, 1.0, 0.5, 0.25])\n",
    "    \n",
    "    torsion_hists_train.append(htrain)\n",
    "    torsion_hists_gen.append(hgen)\n",
    "    \n",
    "torsions_simple = [4, 5, 6, 7, 8]\n",
    "torsions_complex = [0, 1, 2, 10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(nrows=2, ncols=5, sharex=True, figsize=(15, 5))\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, sharey=True, sharex=True, figsize=(15, 3))\n",
    "axes = axes.reshape((1, 5))\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.15)\n",
    "#for row, torsion_index in zip([0, 1], [torsions_simple, torsions_complex]):\n",
    "for row, torsion_index in zip([0], [torsions_complex]):\n",
    "    for i, ax in enumerate(axes[row]):\n",
    "        ax.plot(xticks, torsion_hists_train[torsion_index[i]], color='grey', linewidth=5)\n",
    "        ax.plot(xticks, torsion_hists_gen[torsion_index[i]], color='red', linewidth=3)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(-np.pi, np.pi)\n",
    "        if row == 0:\n",
    "            ax.set_ylim(0, 5)\n",
    "        if row == 1:\n",
    "            ax.set_ylim(0, 1.5)\n",
    "        if row == 1:\n",
    "            ax.set_xticks((-np.pi,0, np.pi))\n",
    "            ax.set_xticklabels(('$-\\pi$', 0,'$\\pi$'))\n",
    "    axes[-1,-1].set_yticks([])\n",
    "axes[0, 0].set_ylim(0, 1.5)\n",
    "axes[0, 0].text(0, 1.35, '$\\phi$')\n",
    "axes[0, 1].text(0, 1.35, '$\\gamma_1$')\n",
    "axes[0, 2].text(0, 1.35, '$\\psi$')\n",
    "axes[0, 3].text(0, 1.35, '$\\gamma_2$')\n",
    "axes[0, 4].text(0, 1.35, '$\\gamma_3$')\n",
    "axes[0, 0].set_ylabel('density')\n",
    "#axes[1, 0].set_ylabel('density')\n",
    "axes[0, -1].text(-np.pi+0.3, 1.1, 'Target', color='grey')\n",
    "axes[0, -1].text(-np.pi+0.3, 0.7, 'RNVP + MCMC', color='red')\n",
    "plt.savefig('torsion_angles.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "for i in torsions_complex:\n",
    "    KL_SNF = np.sum(torsion_hists_train[i] * np.log((torsion_hists_train[i]+eps) / (torsion_hists_gen[i]+eps)))\n",
    "    print(\"{:1.2f}\".format(KL_SNF))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
