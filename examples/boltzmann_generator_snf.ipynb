{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import mdtraj\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/var/home/vs488/Documents/boltzmann/code/boltzmann-generators/')\n",
    "import boltzgen.zmatrix as zmatrix\n",
    "import boltzgen.internal as ics\n",
    "import boltzgen.mixed as mixed\n",
    "\n",
    "import normflow as nf\n",
    "from boltzgen.flows import CoordinateTransform\n",
    "from boltzgen.distributions import Boltzmann, BoltzmannParallel, TransformedBoltzmann, TransformedBoltzmannParallel\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from autograd import grad\n",
    "from autograd import numpy as np\n",
    "from simtk import openmm as mm\n",
    "from simtk import unit\n",
    "from simtk.openmm import app\n",
    "from openmmtools.testsystems import AlanineDipeptideVacuum\n",
    "\n",
    "# Load the alanine dipeptide trajectory\n",
    "aldp_traj = mdtraj.load('/scratch2/vs488/flow/alanine_dipeptide/trajectory/aldp100000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up coordinate transformation\n",
    "\n",
    "z_matrix = [\n",
    "    (1, [4, 5, 6]),\n",
    "    (0, [1, 4, 5]),\n",
    "    (2, [1, 0, 4]),\n",
    "    (3, [1, 0, 2]),\n",
    "    (7, [6, 4, 5]),\n",
    "    (9, [8, 6, 7]),\n",
    "    (10, [8, 6, 9]),\n",
    "    (11, [10, 8, 9]),\n",
    "    (12, [10, 8, 11]),\n",
    "    (13, [10, 11, 12]),\n",
    "    (17, [16, 14, 15]),\n",
    "    (19, [18, 16, 17]),\n",
    "    (20, [18, 19, 16]),\n",
    "    (21, [18, 19, 20])\n",
    "]\n",
    "\n",
    "backbone_indices = [4, 5, 6, 8, 14, 15, 16, 18]\n",
    "\n",
    "aldp_traj.center_coordinates()\n",
    "\n",
    "# superpose on the backbone\n",
    "ind = aldp_traj.top.select(\"backbone\")\n",
    "\n",
    "aldp_traj.superpose(aldp_traj, 0, atom_indices=ind, ref_atom_indices=ind)\n",
    "\n",
    "# Gather the training data into a pytorch Tensor with the right shape\n",
    "training_data = aldp_traj.xyz\n",
    "n_atoms = training_data.shape[1]\n",
    "n_dim = n_atoms * 3\n",
    "training_data_npy = training_data.reshape(-1, n_dim)\n",
    "training_data = torch.from_numpy(training_data_npy.astype(\"float64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up simulation object for energy computation\n",
    "\n",
    "temperature = 1000\n",
    "\n",
    "testsystem = AlanineDipeptideVacuum()\n",
    "implicit_sim = app.Simulation(testsystem.topology,\n",
    "                              testsystem.system,\n",
    "                              mm.LangevinIntegrator(temperature * unit.kelvin , 1.0 / unit.picosecond, 1.0 * unit.femtosecond),\n",
    "                              mm.Platform.getPlatformByName('Reference')#,\n",
    "                              #{'Precision': 'double'}\n",
    "                              )\n",
    "implicit_sim.context.setPositions(testsystem.positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up model\n",
    "\n",
    "# Define flows\n",
    "K = 5\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Set prior and q0\n",
    "p = Boltzmann(implicit_sim.context, temperature, energy_cut=1e2, energy_max=1e20)\n",
    "transform = CoordinateTransform(training_data, 66, z_matrix, backbone_indices)\n",
    "p_ = TransformedBoltzmannParallel(testsystem, temperature, energy_cut=1e2,\n",
    "                                  energy_max=1e20, transform=transform)\n",
    "p__ = BoltzmannParallel(testsystem, temperature, energy_cut=1e2, energy_max=1e20)\n",
    "\n",
    "latent_size = 60\n",
    "hidden_units = 128\n",
    "q0 = nf.distributions.DiagGaussian(latent_size, trainable=False)\n",
    "\n",
    "b = torch.Tensor([1 if i % 2 == 0 else 0 for i in range(latent_size)])\n",
    "flows = []\n",
    "for i in range(K):\n",
    "    # Add two alternating Real NVP layers, and ActNorm layer, and a MCMC layer\n",
    "    # Real NVP layers\n",
    "    s = nf.nets.MLP([latent_size, hidden_units, hidden_units, hidden_units, latent_size])\n",
    "    t = nf.nets.MLP([latent_size, hidden_units, hidden_units, hidden_units, latent_size])\n",
    "    flows += [nf.flows.MaskedAffineFlow(b, s, t)]\n",
    "    s = nf.nets.MLP([latent_size, hidden_units, hidden_units, hidden_units, latent_size])\n",
    "    t = nf.nets.MLP([latent_size, hidden_units, hidden_units, hidden_units, latent_size])\n",
    "    flows += [nf.flows.MaskedAffineFlow(1 - b, s, t)]\n",
    "    # ActNorm\n",
    "    flows += [nf.flows.ActNorm(latent_size)]\n",
    "    # MCMC layer\n",
    "    dist = nf.distributions.LinearInterpolation(p_, q0, (i + 1) / K)\n",
    "    proposal = nf.distributions.DiagGaussianProposal((latent_size,),\n",
    "                                                     0.1 * np.ones(latent_size))\n",
    "    flows += [nf.flows.MetropolisHastings(dist, proposal, 20)]\n",
    "flows += [transform]\n",
    "\n",
    "# Construct flow model\n",
    "nfm = nf.NormalizingFlow(q0=q0, flows=flows, p=p)\n",
    "\n",
    "# Move model on GPU if available\n",
    "enable_cuda = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n",
    "nfm = nfm.to(device)\n",
    "nfm = nfm.double()\n",
    "\n",
    "# Initialize ActNorm\n",
    "ind = torch.randint(len(training_data), (256, ))\n",
    "x = training_data[ind, :].double().to(device)\n",
    "from time import time\n",
    "t = time()\n",
    "kld = nfm.forward_kld(x)\n",
    "print(time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "num_samples = 32\n",
    "max_iter = 10\n",
    "trans_iter = 8000\n",
    "n_data = len(training_data)\n",
    "eval_rkld = 10\n",
    "\n",
    "\n",
    "loss_hist = np.array([])\n",
    "fkld_hist = np.array([])\n",
    "rkld_hist = np.array([])\n",
    "\n",
    "optimizer = torch.optim.AdamW(nfm.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "for it in tqdm(range(max_iter)):\n",
    "    #nfm.p.alpha = np.max([0., 1 - it / trans_iter])\n",
    "    optimizer.zero_grad()\n",
    "    ind = torch.randint(n_data, (batch_size, ))\n",
    "    x = training_data[ind, :].double().to(device)\n",
    "    fkld = nfm.forward_kld(x)\n",
    "    #rkld = nfm.reverse_kld(num_samples=num_samples)\n",
    "    loss = fkld #+ rkld\n",
    "    if not torch.isnan(loss) and loss < 0:\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_value_(nfm.parameters(), .01)\n",
    "        #gradient_norm = torch.nn.utils.clip_grad.clip_grad_norm_(nfm.parameters(), 100.)\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n",
    "    fkld_hist = np.append(fkld_hist, fkld.to('cpu').data.numpy())\n",
    "    #rkld_hist = np.append(rkld_hist, rkld.to('cpu').data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist[loss_hist > 0] = np.nan\n",
    "plt.plot(loss_hist)\n",
    "plt.show()\n",
    "#plt.plot(fkld_hist)\n",
    "#plt.show()\n",
    "#plt.plot(rkld_hist)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfm.eval()\n",
    "z, _ = nfm.sample(10000)\n",
    "z, _ = nfm.flows[-1].inverse(z)\n",
    "z_d, _ = nfm.flows[-1].inverse(training_data[::50].double().to(device))\n",
    "z_np = z.cpu().data.numpy()\n",
    "z_d_np = z_d.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(60):\n",
    "    print(i)\n",
    "    plt.hist(z_d_np[:, i], bins=100, alpha=0.5, label='data', range=[-3.1, 3.1])\n",
    "    plt.hist(z_np[:, i], bins=100, alpha=0.5, label='samples', range=[-3.1, 3.1])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(60):\n",
    "    print(i)\n",
    "    plt.hist(z_d_np[:, i], bins=100, alpha=0.5, label='data', range=[-3.1, 3.1])\n",
    "    plt.hist(z_np[:, i], bins=100, alpha=0.5, label='samples', range=[-3.1, 3.1])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
