{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import mdtraj\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/var/home/vs488/Documents/boltzmann/code/boltzmann-generators/')\n",
    "import boltzgen.zmatrix as zmatrix\n",
    "import boltzgen.internal as ics\n",
    "import boltzgen.mixed as mixed\n",
    "\n",
    "import normflow as nf\n",
    "from boltzgen.flows import CoordinateTransform\n",
    "from boltzgen.distributions import Boltzmann\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from autograd import grad\n",
    "from autograd import numpy as np\n",
    "from openmmtools.constants import kB\n",
    "from simtk import openmm as mm\n",
    "from simtk import unit\n",
    "from simtk.openmm import app\n",
    "from openmmtools.testsystems import AlanineDipeptideImplicit\n",
    "\n",
    "import boltzgen.openmm_interface as omi\n",
    "\n",
    "# Load the alanine dipeptide trajectory\n",
    "aldp_traj = mdtraj.load('/scratch2/vs488/flow/alanine_dipeptide/trajectory/aldp100000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up coordinate transformation\n",
    "\n",
    "z_matrix = [\n",
    "    (1, [4, 5, 6]),\n",
    "    (0, [1, 4, 5]),\n",
    "    (2, [1, 0, 4]),\n",
    "    (3, [1, 0, 2]),\n",
    "    (7, [6, 4, 5]),\n",
    "    (9, [8, 6, 7]),\n",
    "    (10, [8, 6, 9]),\n",
    "    (11, [10, 8, 9]),\n",
    "    (12, [10, 8, 11]),\n",
    "    (13, [10, 11, 12]),\n",
    "    (17, [16, 14, 15]),\n",
    "    (19, [18, 16, 17]),\n",
    "    (20, [18, 19, 16]),\n",
    "    (21, [18, 19, 20])\n",
    "]\n",
    "\n",
    "backbone_indices = [4, 5, 6, 8, 14, 15, 16, 18]\n",
    "\n",
    "aldp_traj.center_coordinates()\n",
    "\n",
    "# superpose on the backbone\n",
    "ind = aldp_traj.top.select(\"backbone\")\n",
    "\n",
    "aldp_traj.superpose(aldp_traj, 0, atom_indices=ind, ref_atom_indices=ind)\n",
    "\n",
    "# Gather the training data into a pytorch Tensor with the right shape\n",
    "training_data = aldp_traj.xyz\n",
    "n_atoms = training_data.shape[1]\n",
    "n_dim = n_atoms * 3\n",
    "training_data_npy = training_data.reshape(-1, n_dim)\n",
    "training_data = torch.from_numpy(training_data_npy.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up simulation object for energy computation\n",
    "\n",
    "temperature = 298\n",
    "kT = kB * temperature\n",
    "\n",
    "testsystem = AlanineDipeptideImplicit()\n",
    "implicit_sim = app.Simulation(testsystem.topology,\n",
    "                              testsystem.system,\n",
    "                              mm.LangevinIntegrator(temperature * unit.kelvin , 1.0 / unit.picosecond, 1.0 * unit.femtosecond),\n",
    "                              platform=mm.Platform.getPlatformByName('CPU')\n",
    "                              )\n",
    "implicit_sim.context.setPositions(testsystem.positions)\n",
    "\n",
    "# Energy function\n",
    "openmm_energy = omi.OpenMMEnergyInterface.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up flow model\n",
    "\n",
    "# Define flows\n",
    "K = 8\n",
    "torch.manual_seed(0)\n",
    "\n",
    "latent_size = 60\n",
    "b = torch.Tensor([1 if i % 2 == 0 else 0 for i in range(latent_size)])\n",
    "flows = []\n",
    "for i in range(K):\n",
    "    s = nf.nets.MLP([latent_size, 4 * latent_size, 4 * latent_size, latent_size])\n",
    "    t = nf.nets.MLP([latent_size, 4 * latent_size, 4 * latent_size, latent_size])\n",
    "    if i % 2 == 0:\n",
    "        flows += [nf.flows.MaskedAffineFlow(b, s, t)]\n",
    "    else:\n",
    "        flows += [nf.flows.MaskedAffineFlow(1 - b, s, t)]\n",
    "    #flows += [nf.flows.Planar(latent_size)]\n",
    "    flows += [nf.flows.ActNorm(latent_size)]\n",
    "flows += [CoordinateTransform(training_data, 66, z_matrix, backbone_indices)]\n",
    "\n",
    "# Set prior and q0\n",
    "prior = Boltzmann(implicit_sim.context, temperature, energy_cut=1e2, energy_max=1e20)\n",
    "q0 = nf.distributions.DiagGaussian(latent_size)\n",
    "\n",
    "# Construct flow model\n",
    "nfm = nf.NormalizingFlow(q0=q0, flows=flows, p=prior)\n",
    "\n",
    "# Move model on GPU if available\n",
    "enable_cuda = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n",
    "nfm = nfm.to(device)\n",
    "nfm = nfm.double()\n",
    "\n",
    "ind = torch.randint(len(training_data), (128, ))\n",
    "x = training_data[ind, :].double()\n",
    "kld = nfm.forward_kld(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "batch_size = 128\n",
    "max_iter = 50000\n",
    "n_data = len(training_data)\n",
    "eval_rkld = 10\n",
    "\n",
    "\n",
    "#loss_hist = np.array([])\n",
    "#fkld_hist = np.array([])\n",
    "#rkld_hist = np.array([])\n",
    "\n",
    "#optimizer = torch.optim.AdamW(nfm.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "for it in tqdm(range(max_iter)):\n",
    "    optimizer.zero_grad()\n",
    "    ind = torch.randint(n_data, (batch_size, ))\n",
    "    x = training_data[ind, :].double()\n",
    "    fkld = nfm.forward_kld(x)\n",
    "    loss = fkld\n",
    "    if not torch.isnan(loss):\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(nfm.parameters(), .1)\n",
    "        gradient_norm = torch.nn.utils.clip_grad.clip_grad_norm_(nfm.parameters(), 100.)\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n",
    "    fkld_hist = np.append(fkld_hist, fkld.to('cpu').data.numpy())\n",
    "    if (it + 1) % eval_rkld == 0:\n",
    "        rkld = nfm.reverse_kld(num_samples=batch_size)\n",
    "        rkld_hist = np.append(rkld_hist, rkld.to('cpu').data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_hist[loss_hist > 0] = np.nan\n",
    "plt.plot(loss_hist)\n",
    "plt.show()\n",
    "plt.plot(fkld_hist[1000:100000])\n",
    "plt.show()\n",
    "plt.plot(rkld_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfm.load('/scratch2/vs488/flow/alanine_dipeptide/models/real_nvp_ml_100000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, log_q = nfm.sample(50000)\n",
    "z_d = training_data[::2, :].double()\n",
    "log_p = nfm.p.log_prob(z)\n",
    "log_p_d = nfm.p.log_prob(z_d)\n",
    "log_q_d = nfm.log_prob(z_d)\n",
    "E_np = -log_p.data.numpy()\n",
    "E_q_np = -log_q.data.numpy()\n",
    "E_q_d_np = -log_q_d.data.numpy()\n",
    "E_d_np = -log_p_d.data.numpy()\n",
    "w = torch.exp(log_p - log_q)\n",
    "w_np = w.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(E_d_np, bins=100, alpha=0.5, label='data', range=[-0.03, -0.005])\n",
    "plt.hist(E_np, bins=100, alpha=0.5, label='samples, -log(p)', range=[-0.03, -0.005])\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('E_dist_p.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(E_q_d_np, bins=100, alpha=0.5, label='data, -log(q)', range=[-400, -300])\n",
    "plt.hist(E_q_np, bins=100, alpha=0.5, label='samples, -log(q)', range=[-400, -300])\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('E_dist_q.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z, _ = nfm.sample(100000)\n",
    "z, _ = nfm.flows[-1].inverse(z)\n",
    "z_d, _ = nfm.flows[-1].inverse(training_data.double())\n",
    "z_np = z.data.numpy()\n",
    "z_d_np = z_d.data.numpy()\n",
    "\n",
    "for i in range(60):\n",
    "    print(i)\n",
    "    print(np.mean(z_d_np[:, i]))\n",
    "    plt.hist(z_d_np[:, i], bins=100, alpha=0.5, label='data')#, range=[-3.1, 3.1])\n",
    "    plt.hist(z_np[:, i], bins=100, alpha=0.5, label='samples')#, range=[-3.1, 3.1])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
